{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rbCQRwO4kN-L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r1R7TV5lkQbA"
      },
      "outputs": [],
      "source": [
        "# --- Load Labels ---\n",
        "augmented_df = pd.read_csv(\"D:/SE/Data/screenshots/augmented_data/labels.txt\", header=None, names=[\"filename\", \"emoji\", \"unicode\"], sep=\",\\s*\", engine='python')\n",
        "original_df = pd.read_csv(\"D:/SE/Data/screenshots/screenshots10cropped/labels.txt\", header=None, names=[\"filename\", \"emoji\", \"unicode\"], sep=\",\\s*\", engine='python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "InR7o9L_kSzg"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "augmented_df['encoded_unicode'] = le.fit_transform(augmented_df['unicode'])\n",
        "original_df['encoded_unicode'] = le.transform(original_df['unicode'])  # Match encodings\n",
        "num_classes = len(le.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VjBpFQA3kVed"
      },
      "outputs": [],
      "source": [
        "# --- Custom Dataset Class ---\n",
        "class EmojiDataset(Sequence):\n",
        "    def __init__(self, df, img_dir, batch_size=32, img_size=(64, 64), shuffle=True):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_data = self.df.iloc[batch_indexes]\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for _, row in batch_data.iterrows():\n",
        "            img_path = os.path.join(self.img_dir, row['filename'])\n",
        "            image = load_img(img_path, target_size=self.img_size)\n",
        "            image = img_to_array(image) / 255.0\n",
        "            images.append(image)\n",
        "            labels.append(row['encoded_unicode'])\n",
        "\n",
        "        return np.array(images), to_categorical(np.array(labels), num_classes=num_classes)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrbE2XfXkYZO",
        "outputId": "fe5e343a-f234-41c5-c5c2-be5fb9e07504"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aliza\\tf-env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# --- Model Definition ---\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- Dataset Generators ---\n",
        "train_generator = EmojiDataset(augmented_df, img_dir='D:/SE/Data/screenshots/augmented_data/', batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iX-W8-3Dkbbh"
      },
      "outputs": [],
      "source": [
        "# --- Manual Testing ---\n",
        "def test_model_accuracy(model, df, img_dir):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = len(df)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        img_path = os.path.join(img_dir, row['filename'])\n",
        "        img = load_img(img_path, target_size=(64, 64))\n",
        "        img = img_to_array(img) / 255.0\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        predicted_class = np.argmax(model.predict(img, verbose=0), axis=-1)[0]\n",
        "        actual_class = row['encoded_unicode']\n",
        "\n",
        "        if predicted_class == actual_class:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions * 100\n",
        "    print(f\"\\nModel Accuracy (on original images): {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oUIiYByWkeV1"
      },
      "outputs": [],
      "source": [
        "# --- Accuracy Callback ---\n",
        "class AccuracyTestingCallback(Callback):\n",
        "    def __init__(self, df, img_dir, interval=10):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.interval = interval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.interval == 0:\n",
        "            print(f\"\\nTesting accuracy after epoch {epoch + 1}...\")\n",
        "            test_model_accuracy(self.model, self.df, self.img_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import os\n",
        "\n",
        "class SaveEveryNEpochs(Callback):\n",
        "    def __init__(self, save_freq, save_path_template):\n",
        "        super().__init__()\n",
        "        self.save_freq = save_freq\n",
        "        self.save_path_template = save_path_template\n",
        "        os.makedirs(os.path.dirname(save_path_template), exist_ok=True)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.save_freq == 0:\n",
        "            path = self.save_path_template.format(epoch=epoch + 1)\n",
        "            self.model.save(path)\n",
        "            print(f'\\n✅ Saved model at: {path}')\n",
        "\n",
        "# --- Callbacks ---\n",
        "accuracy_callback = AccuracyTestingCallback(original_df, 'D:/SE/Data/screenshots/screenshots10cropped/', interval=10)\n",
        "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "checkpoint_callback = SaveEveryNEpochs(save_freq=5, save_path_template='model_checkpoints/model_epoch_{epoch:02d}.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "QYsdsQNci4oF",
        "outputId": "e85a813a-cbf5-4717-bcfe-24ef3633a3c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aliza\\tf-env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 374ms/step - accuracy: 0.0392 - loss: 6.7501 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 160ms/step - accuracy: 0.4448 - loss: 2.6172 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 163ms/step - accuracy: 0.6733 - loss: 1.2728 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 164ms/step - accuracy: 0.7538 - loss: 0.8928 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7838 - loss: 0.7458"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Saved model at: model_checkpoints/model_epoch_05.h5\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 162ms/step - accuracy: 0.7838 - loss: 0.7458 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 161ms/step - accuracy: 0.8170 - loss: 0.6195 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 161ms/step - accuracy: 0.8330 - loss: 0.5556 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 162ms/step - accuracy: 0.8502 - loss: 0.4925 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 162ms/step - accuracy: 0.8607 - loss: 0.4530 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8712 - loss: 0.4153\n",
            "Testing accuracy after epoch 10...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Accuracy (on original images): 94.22%\n",
            "\n",
            "✅ Saved model at: model_checkpoints/model_epoch_10.h5\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 302ms/step - accuracy: 0.8712 - loss: 0.4153 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 160ms/step - accuracy: 0.8803 - loss: 0.3883 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 161ms/step - accuracy: 0.8860 - loss: 0.3716 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 162ms/step - accuracy: 0.8914 - loss: 0.3497 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 161ms/step - accuracy: 0.8986 - loss: 0.3286 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9025 - loss: 0.3113"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Saved model at: model_checkpoints/model_epoch_15.h5\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 164ms/step - accuracy: 0.9025 - loss: 0.3113 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 160ms/step - accuracy: 0.9058 - loss: 0.3005 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 159ms/step - accuracy: 0.9105 - loss: 0.2868 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 160ms/step - accuracy: 0.9169 - loss: 0.2673 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 161ms/step - accuracy: 0.9192 - loss: 0.2639 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9236 - loss: 0.2480\n",
            "Testing accuracy after epoch 20...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Accuracy (on original images): 95.12%\n",
            "\n",
            "✅ Saved model at: model_checkpoints/model_epoch_20.h5\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 281ms/step - accuracy: 0.9236 - loss: 0.2480 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 159ms/step - accuracy: 0.9278 - loss: 0.2355 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 161ms/step - accuracy: 0.9277 - loss: 0.2311 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 160ms/step - accuracy: 0.9271 - loss: 0.2379 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 161ms/step - accuracy: 0.9363 - loss: 0.2090 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9316 - loss: 0.2178"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Saved model at: model_checkpoints/model_epoch_25.h5\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 161ms/step - accuracy: 0.9316 - loss: 0.2178 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 159ms/step - accuracy: 0.9341 - loss: 0.2054 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 159ms/step - accuracy: 0.9406 - loss: 0.1852 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 160ms/step - accuracy: 0.9412 - loss: 0.1953 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 162ms/step - accuracy: 0.9404 - loss: 0.1893 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9419 - loss: 0.1810\n",
            "Testing accuracy after epoch 30...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Accuracy (on original images): 95.76%\n",
            "\n",
            "✅ Saved model at: model_checkpoints/model_epoch_30.h5\n",
            "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 280ms/step - accuracy: 0.9419 - loss: 0.1810 - learning_rate: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2b7957a8510>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Train Model ---\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    callbacks=[accuracy_callback, early_stop, reduce_lr, checkpoint_callback]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
